# Feature-Selection 
Feature Selection is simply selecting subset of the original data features and discarding the less important ones, that will help reduce dimensions in data, simplify data, decrease computational cost, and increase accuracy of ML models.


## Types of Feature Selection Techniques


### 1. Filter Based

where the features are evaluated only by statistical methods, before any machine learning algorithm. for this type we will discuss:
\
- Variance threshold
- Pearson's Correlation
- Chi-squared
- Information Gain (IG)

\
![image](https://github.com/user-attachments/assets/d96ac008-33af-431e-8ed3-2e54e375eb83)



### 2. Wrapper Based

where the features are evaluated by evaluating the machine learning model performance, if the feature is increasing the model performance, keep it, else discard it. for this type we will discuss:
\
- Forward Selection
- Backward Selection

\
![image](https://github.com/user-attachments/assets/4177f81d-b017-436e-9046-5346b481eb54)



### 3. Embedded Methods

